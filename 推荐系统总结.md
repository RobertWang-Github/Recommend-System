简单来说,推荐是个分类问题,待推荐的对象item和人person之间构成特征二元组(item_i,person_i),而click与否则是标签(c_i).  
然而,如果考虑到click和order的差异,我们需要最大化  
<a href="https://www.codecogs.com/eqnedit.php?latex=income&space;=&space;P(click|impression)*P(order|click)*price" target="_blank"><img src="https://latex.codecogs.com/gif.latex?income&space;=&space;P(click|impression)*P(order|click)*price" title="income = P(click|impression)*P(order|click)*price" /></a>  
impression(曝光)->click(点击)->order(实现) * price(价格) 才是我们需要的收益.

下面对几个的推荐系统作总结:  


1.FM(Factorization Machines 因子分解机)  
&emsp;&emsp;1.线性部分(将各特征线性加权,显然线性部分直接用sigmoid激活就是LR)  
&emsp;&emsp;&emsp;&emsp;<a href="https://www.codecogs.com/eqnedit.php?latex=y_linear&space;=&space;\sigma(<\overrightarrow{w},\overrightarrow{x}>))" target="_blank"><img src="https://latex.codecogs.com/gif.latex?y_linear&space;=&space;<\overrightarrow{w},\overrightarrow{x}>" title="y_linear = <\overrightarrow{w},\overrightarrow{x}>" /></a>  
&emsp;&emsp;2.二阶部分(各特征两两组合(此处以乘积形式))  
&emsp;&emsp;&emsp;&emsp;<a href="https://www.codecogs.com/eqnedit.php?latex=y_{2d-polynomial}&space;=&space;\overrightarrow{x}^T*W^{(2)}*\overrightarrow{x}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?y_{2d-polynomial}&space;=&space;\overrightarrow{x}^T*W^{(2)}*\overrightarrow{x}" title="y_{2d-polynomial} = \overrightarrow{x}^T*W^{(2)}*\overrightarrow{x}" /></a>  
&emsp;&emsp;&emsp;&emsp;<img src="https://latex.codecogs.com/gif.latex?W^{(2)}" title="W^{(2)}" /></a>是一个n阶对称阵,因为任何两个特征x_i和x_j的关系是对称的.  
&emsp;&emsp;&emsp;&emsp;那么,<img src="https://latex.codecogs.com/gif.latex?W^{(2)}" title="W^{(2)}" /></a>可以分解为W^T * W.W为(n,k)二阶张量.原函数形式就变成了  
&emsp;&emsp;&emsp;&emsp;<a href="https://www.codecogs.com/eqnedit.php?latex=y_{2d-polynomial}&space;=&space;\overrightarrow{x}^T*W^T*W*\overrightarrow{x}=<W*\overrightarrow{x},W*\overrightarrow{x}>" target="_blank"><img src="https://latex.codecogs.com/gif.latex?y_{2d-polynomial}&space;=&space;\overrightarrow{x}^T*W^T*W*\overrightarrow{x}=<W*\overrightarrow{x},W*\overrightarrow{x}>" title="y_{2d-polynomial} = \overrightarrow{x}^T*W^T*W*\overrightarrow{x}=<W*\overrightarrow{x},W*\overrightarrow{x}>" /></a>  
<a href="https://www.codecogs.com/eqnedit.php?latex=W*\overrightarrow{x}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?W*\overrightarrow{x}" title="W*\overrightarrow{x}" /></a>可以看做是将向量x映射到低维(k维度)空间,因为W的每个行向量此时为一个基.如此,如果x是个高维稀疏向量,就被映射到了低维空间,此时再计算两两关系就会节省计算量.显然,这个低维空间是被训练的,以拿到最适合的向量表示.  
&emsp;&emsp;&emsp;&emsp;计算上来说,W*\overrightarrow{x}可以看作W的列向量按照x的分量线性加权.那么原式计算可以优化为<a href="https://www.codecogs.com/eqnedit.php?latex=y_{2d-ploynomial}=\sum_{i=1}^{n}\sum_{j=1}^{n}<\overrightarrow{v_i},\overrightarrow{v_j}>x_i*x_j" target="_blank"><img src="https://latex.codecogs.com/gif.latex?y_{2d-ploynomial}=\sum_{i=1}^{n}\sum_{j=1}^{n}<\overrightarrow{v_i},\overrightarrow{v_j}>x_i*x_j" title="y_{2d-ploynomial}=\sum_{i=1}^{n}\sum_{j=1}^{n}<\overrightarrow{v_i},\overrightarrow{v_j}>x_i*x_j" /></a>  
&emsp;&emsp;&emsp;&emsp;其中,v_i和v_j皆为W的列向量.  





&emsp;&emsp;3.输出部分(采用sigmoid作为激活函数)  
&emsp;&emsp;&emsp;&emsp;  

2.FFM  




3.DeepFM  










0.标签匹配(此时就不得不介绍下本人的原创方法)  
&emsp;&emsp;1.给item打上标签,此时每个类下的标签都会有一个经验分布(由频数或者分数归一化得到).具体哪些标签算作一类要由规则确定.假如是类为行业关键词,那么这些词就构成了这个类下的标签.
&emsp;&emsp;2.搜集用户person在item上的信息(即将每个用户在过去某个时间段内浏览的item的标签分类汇总,拿到每个类下标签的经验分布)  
&emsp;&emsp;3.依据person的各类下的概率分布和item的各类下的概率分布,按item标签的来源基于不同权重,各类予以不同权重,类内采用命中标签的概率值相乘的方式获取分数,再将该分数和类与来源的权重层层加权,最后将总分数排序,作为推荐候选名单.  
&emsp;&emsp;4.也可以将person和item的概率分布计算交叉熵作为分数进行加权.  
&emsp;&emsp;5.也可以将person和item的概率分布作为特征传入分类算法.  





